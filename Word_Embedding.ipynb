{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation Of Word Embedding "
      ],
      "metadata": {
        "id": "I2UrOJH0Mu7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Important Packages"
      ],
      "metadata": {
        "id": "lnmPbramM5jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "metadata": {
        "id": "_Gvx-4lyxp5n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Embedding Class"
      ],
      "metadata": {
        "id": "kb9Ra5F5NA2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Word_Embedding:\n",
        "  def __init__(self, context_word_size):\n",
        "    self.window_size = 2*context_word_size + 1\n",
        "    self.vocabulary = set()\n",
        "\n",
        "\n",
        "  def preprocessing(self, data):\n",
        "    preprocessed_data = {'data':[], 'labels':[]}\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    for row in data:\n",
        "      row = row.lower()\n",
        "      list_ = tokenizer.tokenize(row)\n",
        "      list_ = self.remove_digits(list_)\n",
        "      self.add_to_vocabulary(list_)\n",
        "      data, labels = self.extract_data_from_window(list_, self.window_size)\n",
        "      preprocessed_data['data'] += data\n",
        "      preprocessed_data['labels'] += labels\n",
        "\n",
        "    for index in range(len(preprocessed_data['labels'])):\n",
        "      preprocessed_data['data'][index] = self.sent_to_vec(preprocessed_data['data'][index], list(self.vocabulary))\n",
        "      preprocessed_data['labels'][index] = self.word_to_vec(preprocessed_data['labels'][index], list(self.vocabulary))\n",
        "\n",
        "    return preprocessed_data\n",
        "\n",
        "\n",
        "  def add_to_vocabulary(self, list_):\n",
        "    for item in list_:\n",
        "      self.vocabulary.add(item)\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def remove_digits(list_):\n",
        "    new_list = []\n",
        "    for item in list_:\n",
        "      if not item.isdigit():\n",
        "        new_list.append(item)\n",
        "\n",
        "    return new_list\n",
        "\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def extract_data_from_window(list_, window_size):\n",
        "    extracted_data = ([],[])\n",
        "    index = 0\n",
        "    while index + window_size  <= len(list_):\n",
        "      window = list_[index : index + window_size]\n",
        "      center_word = window.pop((window_size + 1)//2)\n",
        "      extracted_data[0].append(window)\n",
        "      extracted_data[1].append(center_word)\n",
        "      index += 1\n",
        "\n",
        "    return extracted_data\n",
        "\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def sent_to_vec(list_, vocabulary):\n",
        "    sent_vec = np.zeros(len(vocabulary))\n",
        "    for word in list_:\n",
        "      sent_vec += Word_Embedding.word_to_vec(word, vocabulary)\n",
        "    \n",
        "    return sent_vec / len(list_)\n",
        "\n",
        "  @staticmethod\n",
        "  def word_to_vec(word, vocabulary):\n",
        "    if word not in vocabulary:\n",
        "      raise ValueError(f'word {0} not in vocabulary list'.format(word))\n",
        "    word_vec = np.zeros(len(vocabulary), int)\n",
        "    word_vec[vocabulary.index(word)] = 1\n",
        "    return word_vec\n"
      ],
      "metadata": {
        "id": "avJiJMPMAgU2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word_Embedding(context_word_size=2)\n",
        "model.preprocessing(['Play the Instrumental Study on Vimeo'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOCzYGq8AXLH",
        "outputId": "dcb4be4a-c597-4d84-a5b1-c019c57ad62f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': [array([0.  , 0.25, 0.25, 0.  , 0.25, 0.25]),\n",
              "  array([0.25, 0.  , 0.25, 0.25, 0.25, 0.  ])],\n",
              " 'labels': [array([1, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 1])]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAPjDNPbR9O2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}